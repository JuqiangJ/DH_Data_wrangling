[
["index.html", "An Introduction to Data wrangling with R Chapter 1 Prerequisites 1.1 Installing R and R studio 1.2 Installing libraries in R 1.3 Install packages and library packages 1.4 Programme", " An Introduction to Data wrangling with R Juqiang Chen 2019-08-30 Chapter 1 Prerequisites This document is to accompany An introduction to data wrangling with R tutorial for DH Downunder 2019 at the University of Newcastle, Australia, from 9-13 December. I am a speech scientist working on cross-language lexical tone perception and production. I have rich experience dealing with experimental data and I am keen to help others with data wrangling, data visualization and statistical modelling problems. I aspire to promote a streamlined workflow with R packages to improve data analysis efficiency in quantitative analysis in the field of social science and linguistics. If you have any questions about the tutorial, please e-mail me at: j.chen2@westernsydney.edu.au Good data are somewhat alike but messy data are messy in different ways. This workshop aims to walk the audience through a streamlined workflow of data wrangling (importing data, cleaning data, transforming data) using popular R packages, such as dplyr and tidyr. It involves an introduction to basic concepts in data analysis, such as variables vs. observations, categorical vs. continuous variables, long vs. wide data. In addition, participants will learn how to (batch) import datasets, select and rename rows and columns, deal with missing data, generate new columns by computing the existing ones, and combine data frames. The pipe operator will be introduced to improve the efficiency and clarity of coding. Participants will also learn to write their own functions for data wrangling. Exercises and challenges involve real life research problems. Preliminary experience with R will be helpful, though not required. Participants are required to download and install R and R studio before the workshop. Datasets for the workshop are available online before the workshop. Participants are welcomed to bring their own data and apply what they learn on the spot. Before we start our journey of data wrangling with R, you will need to install R on your laptop. R is multi-platform, which means you can install R on your PC or MAC. 1.1 Installing R and R studio Use this link [https://cloud.r-project.org/] to download R and select the proper version for your laptop. knitr::include_graphics(&quot;img/installr.jpg&quot;) Figure 1.1: Download R 1.2 Installing libraries in R RStudio is an integrated development environment, or IDE, for R programming. Download and install it from [http://www.rstudio.com/download.] The free version is poweful enough. 1.3 Install packages and library packages install.packages(“package_name”) library(package_name) 1.4 Programme Session 1 chapter 1 &amp; 2 Session 2 chapter 3, 4 &amp; 5 Session 3 chapter 3, 4 &amp; 5 "],
["intro.html", "Chapter 2 Basic data structures in R 2.1 Nominal, ordinal, interval/ratio variables 2.2 1D data structure: vectors 2.3 2D data structures: matrice and data frames 2.4 summary", " Chapter 2 Basic data structures in R Before we get our hands dirty in doing actual data analysis, it is desirable to take one step back and think about what types of variables and data structures we are dealing with. Before we talk about data structure in R, let’s first think about how data can be categorized. 2.1 Nominal, ordinal, interval/ratio variables Nominal variables are data whose levels are labels or descriptions, and which cannot be ordered. (e.g. sex, school, or nationality). They are categorical in natural with different levels. Ordinal variables can be ordered, or ranked in logical order, but the interval between levels of the variables are not necessarily known. For example, when doing a survey, participants will be asked to rateSubjective measurements are often ordinal variables, e.g. a Likert ranking scale; level of education for adults (“less than high school”, “high school”, “associate’s degree”). We can logically assign numbers to levels of an ordinal variable, and can treat them in order, but shouldn’t treat them as numeric: “strongly agree” and “neutral” may not average out to an “agree.” Interval/ratio variables are measured or counted values: age, height, weight, number of students. The interval between numbers is known to be equal: the interval between one kilogram and two kilograms is the same as between three kilograms and four kilograms. Interval/ratio data are also called “quantitative” data, although ordinal data are also quantitative. Discrete: values are necessarily whole numbers or other discrete values, such as population or counts of items continuous variables: values can take on any value within an interval, and so can be expressed as decimals. They are often measured quantities. For example, in theory a weight could be measured as 1 kg, 1.01 kg, or 1.009 kg, and so on. Age could also be considered a continuous variable, though we often treat it as a discrete variable, by rounding it to the most recent birthday. The variable type will determine (1) statistical analysis; (2) the way we summarize data with statistics and plots. We will be elaborating on this in the Explorative Data Analysis course. Variables can be stored in R in different data types. Normial and ordinal variables can be stored as character data or factors (with levels) whil interval data can be stored as numbers either as integer or numeric (real or decimal). If you have only one variable, you can store it in a vector. More often than not, you have a bunch of variables that should be store or imported as a matrix or data frame. 2.2 1D data structure: vectors A vector is a sequence of data elements of the same basic type: integer, double, logical or character. All elements of a vector must be the same type. 2.2.1 Creating vectors a = 8:17 b &lt;- c(9, 10, 100, 38) c = c (TRUE, FALSE, TRUE, FALSE) c = c (T, F, T, F) d = c (&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;FALSE&quot;) # You can change the type of a vector with as.vector function. as.vector(b, mode = &quot;character&quot;) ## [1] &quot;9&quot; &quot;10&quot; &quot;100&quot; &quot;38&quot; # When you put elements of different types in one vector, R will automatically change the type of some elements to keep the whole vector homogenous. e = c(9,10, &quot;ab&quot;, &quot;cd&quot;) f = c(10, 11, T, F) Some basic function in R that you can play with now to generate vectors. a = 9:20 +1 b = seq (1, 10) c = seq (1, 20, by= 2) d = rep (5, 4) e = rep (c(1,2,3), 4) f = rep (c(1,2,3), each = 4) # Now that you have a vector, you can do some Maths. max(a) ## [1] 21 min(a) ## [1] 10 range(a) ## [1] 10 21 sum(a) ## [1] 186 mean(a) ## [1] 15.5 median(a) ## [1] 15.5 quantile(a) ## 0% 25% 50% 75% 100% ## 10.00 12.75 15.50 18.25 21.00 sd(a) ## [1] 3.605551 round(a, 2) ## [1] 10 11 12 13 14 15 16 17 18 19 20 21 2.2.2 creating list objects We can put vectors of different types (e.g., number, logic or character) and lengths in a list object. list = list(a, b, c, d, e, f) # More often than not, we do not make list ourselves but have to deal with list when we get outputs from stats models. 2.3 2D data structures: matrice and data frames Most of us have some experience with Excel spreadsheet. Data in a spreadsheet are arranged by rows and columns in a rectangular space. This is a typical 2 dimensional data structure. In R, we can have two way of forming tabular data like a spreadsheet: matrix and dataframe. A matrix is a collection of data elements arranged in a two-dimensional rectangular layout and all the elements must be of the same type (e.g., numeric or character). Dataframe is similar to matrix in shape but only differ in that we can have different types of data in each column. Thus, in data analysis, we use dataframe more often than matrix. let’s generate a dataframe from scratch. id = seq(1, 40) gender = rep(c(&quot;male&quot;, &quot;female&quot;), 5) maths = rnorm(40, mean = 70, sd = 5) english = rnorm(40, mean = 80, sd = 9) music = rnorm(40, mean = 75, sd = 10) pe = rnorm(40, mean = 86, sd = 12) df1 = data.frame (id, gender, maths, english) Now let’s explore the data frame we just created. str(df1) ## &#39;data.frame&#39;: 40 obs. of 4 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ gender : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 2 1 2 1 2 1 ... ## $ maths : num 71.3 75.3 68.3 74 70.9 ... ## $ english: num 84.4 107.6 71.9 91.8 71.3 ... summary(df1) ## id gender maths english ## Min. : 1.00 female:20 Min. :58.81 Min. : 57.81 ## 1st Qu.:10.75 male :20 1st Qu.:66.82 1st Qu.: 70.94 ## Median :20.50 Median :70.66 Median : 78.75 ## Mean :20.50 Mean :70.21 Mean : 79.93 ## 3rd Qu.:30.25 3rd Qu.:74.35 3rd Qu.: 87.83 ## Max. :40.00 Max. :81.32 Max. :107.65 nrow(df1) ## [1] 40 ncol(df1) ## [1] 4 attributes(df1) ## $names ## [1] &quot;id&quot; &quot;gender&quot; &quot;maths&quot; &quot;english&quot; ## ## $class ## [1] &quot;data.frame&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ## [24] 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 2.3.1 what if I want to change column names or add variable to the df? df2 = data.frame (id = id, gender = gender, maths = maths, english = english) # cbind(df2, pe) df2 = cbind(df2, pe) colnames(df2) = c(&quot;ID&quot;, &quot;SEX&quot;,&quot;MATHS&quot;,&quot;ENGLISH&quot;,&quot;PE&quot;) head(df2) ## ID SEX MATHS ENGLISH PE ## 1 1 male 71.29029 84.44315 109.38637 ## 2 2 female 75.33467 107.64605 78.51020 ## 3 3 male 68.34809 71.88340 94.20487 ## 4 4 female 74.01717 91.82938 102.54381 ## 5 5 male 70.93575 71.31652 90.24409 ## 6 6 female 63.78425 72.38395 73.44233 # names(df2 ) = c(&quot;ID&quot;, &quot;SEX&quot;,&quot;MATHS&quot;,&quot;ENGLISH&quot;,&quot;PE&quot;) # rownames(df2 ) 2.3.2 Subsetting dataframes We all know how to select part of an Excel spreadsheet by moving our mouse. In R, when we want to select part of a dataframe, we use this formula, dataframe[row, column]. There are various ways we can use this formula and believe it or not, you will love them! df2[2:5, ] ## ID SEX MATHS ENGLISH PE ## 2 2 female 75.33467 107.64605 78.51020 ## 3 3 male 68.34809 71.88340 94.20487 ## 4 4 female 74.01717 91.82938 102.54381 ## 5 5 male 70.93575 71.31652 90.24409 df2[ , 1:2] ## ID SEX ## 1 1 male ## 2 2 female ## 3 3 male ## 4 4 female ## 5 5 male ## 6 6 female ## 7 7 male ## 8 8 female ## 9 9 male ## 10 10 female ## 11 11 male ## 12 12 female ## 13 13 male ## 14 14 female ## 15 15 male ## 16 16 female ## 17 17 male ## 18 18 female ## 19 19 male ## 20 20 female ## 21 21 male ## 22 22 female ## 23 23 male ## 24 24 female ## 25 25 male ## 26 26 female ## 27 27 male ## 28 28 female ## 29 29 male ## 30 30 female ## 31 31 male ## 32 32 female ## 33 33 male ## 34 34 female ## 35 35 male ## 36 36 female ## 37 37 male ## 38 38 female ## 39 39 male ## 40 40 female df2[ , c(&quot;ENGLISH&quot;, &quot;PE&quot;)] ## ENGLISH PE ## 1 84.44315 109.38637 ## 2 107.64605 78.51020 ## 3 71.88340 94.20487 ## 4 91.82938 102.54381 ## 5 71.31652 90.24409 ## 6 72.38395 73.44233 ## 7 82.15357 81.28992 ## 8 80.84380 97.17811 ## 9 70.99685 76.88422 ## 10 96.93514 74.51689 ## 11 57.81487 96.62416 ## 12 78.93862 88.67630 ## 13 87.72476 77.11335 ## 14 71.37986 87.35923 ## 15 66.43607 87.23850 ## 16 83.59176 83.06853 ## 17 62.29301 102.57317 ## 18 78.55796 101.87404 ## 19 69.91184 78.31046 ## 20 93.77672 91.93771 ## 21 70.01296 92.19000 ## 22 81.12185 87.66763 ## 23 86.56035 62.05710 ## 24 91.12286 75.16298 ## 25 83.80946 84.29363 ## 26 87.74601 70.91673 ## 27 92.35360 71.72179 ## 28 69.33522 77.14181 ## 29 77.24202 89.09007 ## 30 90.64900 96.51885 ## 31 78.43136 82.31968 ## 32 68.27859 68.44806 ## 33 88.09032 69.36293 ## 34 70.75372 80.32614 ## 35 97.04300 90.47817 ## 36 67.62429 83.19442 ## 37 78.29391 88.26572 ## 38 70.31824 98.15602 ## 39 91.39948 93.55080 ## 40 76.22584 85.29689 df2[c(1,2,3), ] ## ID SEX MATHS ENGLISH PE ## 1 1 male 71.29029 84.44315 109.38637 ## 2 2 female 75.33467 107.64605 78.51020 ## 3 3 male 68.34809 71.88340 94.20487 df2[seq(1, 40, 2), ] ## ID SEX MATHS ENGLISH PE ## 1 1 male 71.29029 84.44315 109.38637 ## 3 3 male 68.34809 71.88340 94.20487 ## 5 5 male 70.93575 71.31652 90.24409 ## 7 7 male 73.64157 82.15357 81.28992 ## 9 9 male 71.36729 70.99685 76.88422 ## 11 11 male 67.01157 57.81487 96.62416 ## 13 13 male 69.36979 87.72476 77.11335 ## 15 15 male 70.90837 66.43607 87.23850 ## 17 17 male 59.16073 62.29301 102.57317 ## 19 19 male 77.30270 69.91184 78.31046 ## 21 21 male 70.41636 70.01296 92.19000 ## 23 23 male 75.88901 86.56035 62.05710 ## 25 25 male 58.81099 83.80946 84.29363 ## 27 27 male 66.04598 92.35360 71.72179 ## 29 29 male 67.11365 77.24202 89.09007 ## 31 31 male 72.95053 78.43136 82.31968 ## 33 33 male 75.78261 88.09032 69.36293 ## 35 35 male 65.67728 97.04300 90.47817 ## 37 37 male 73.38726 78.29391 88.26572 ## 39 39 male 69.54739 91.39948 93.55080 2.4 summary Dimensions Homogenous Heterogeneous 1D Atomic Vector List 2D Matrix Data frame nD Array "],
["what-is-data-wrangling.html", "Chapter 3 What is data wrangling? 3.1 Data analysis workflow 3.2 Data wrangling", " Chapter 3 What is data wrangling? 3.1 Data analysis workflow A common workflow for data analysis involves importing data, cleaning data, transforming data, visualizing and modeling data for reports or papers. If you have not worked with R before, you may use excel to do data cleaning and simple tranformation work with pivot tables and save the results in a new spreadsheet. You can also draw bar charts, pie charts and histrograms in the spreadsheet and save it as another spreadsheet. Then when you need to do more complex stats modeling like ANOVA or linear regression, you may import the spreadsheet into SPSS and other stats packages. Usually at the end of the project, you will find a number of .xsl or .csv files in your data folder. You may name them with the analysis you do or the data you generate them. But after six months, you may feel unsure about what is the meaning of the files, not to mention, others who may want to use it. This issue involves lots of decision to be made in data management. But if you are using R, things can be easily because each manipulation of the data is recorded and fully reproducible. knitr::include_graphics(&quot;img/DA_workflow.png&quot;) Figure 3.1: Data analysis workflow 3.2 Data wrangling Data wrangling (see the above figure in red box) involves some basic procedures (importing, tidying and transforming) in the early stage of data analysis. R,and relevant packages, tidyverse in particular, provide a number of functions that can help us dealing with data cleaning and tranformation. We will be learning how to use these functions in the follow sessions. "],
["importing-your-data.html", "Chapter 4 Importing your data 4.1 from CSV/TXT 4.2 from EXCEL 4.3 Batch import 4.4 Take a glimpse of the dataframe", " Chapter 4 Importing your data 4.1 from CSV/TXT You can import data in csv (comma seperate) or text files that use a different delimiter to seperate data. There two groups of function you can use: Base R functions readr package functions read.table() is a multipurpose function in R for importing data, and this function has two special cases: read.csv() and read.delim(). read.csv() is a wrapper for read.table with some default settings: sep = “,” ; header = TRUE. read.delim() is a wrapper for read.table with some default settings: sep = “” ; header = TRUE. readr package functions you need to library(readr) readr functions are 10 times faster than basi functions. read_csv(): you can specify col_types = list(col_double(), col_character()), or col_names = c(“a”,“b”) read_delim() read_table() participant_1 &lt;- read.csv(&quot;data/participant_1.csv&quot;) #stringAsFactor = FALSE participant_2 &lt;- read.csv(&quot;data/participant_2.csv&quot;) ## from TXT participant_1_tab &lt;- read.delim(&quot;~/OneDrive_Backup/OneDrive - Western Sydney University/JuqiangCHEN/310_Tutorial/DH_Data_wrangling/data/participant_1_tab.txt&quot;) 4.2 from EXCEL library(readxl) excel_test &lt;- read_excel(&quot;data/excel_test.xlsx&quot;, sheet = &quot;participant_1&quot;) 4.3 Batch import rbind(participant_1, participant_2) all = rbind(participant_1, participant_2) # what about 10 more people? participant_3 &lt;- read.csv(&quot;data/participant_3.csv&quot;) # get all the filenames of the folder getwd() # get working directory paste0(getwd(), &quot;/data&quot;) #specify the directory for the data list.files(paste0(getwd(), &quot;/data&quot;),full.names=T) # full.names=T means getting the full path filename = list.files(paste0(getwd(), &quot;/data&quot;),full.names=T, pattern = &quot;.csv&quot;) # get only csv files # now you need a loop df = data.frame() bin = data.frame() for (i in 1:length(filename)){ # length(filename) = how many files bin = read.csv(filename[i]) df = rbind(df, bin) } 4.4 Take a glimpse of the dataframe R has some basic function that can help us have a quick look at the dataframe import. summary() 1 For each factor variable, the levels are printed. 2 For each numeric variable, the minimun, first quantile, median, mean, third quantile and the maximun values are shown. str() structure This gives the information about the types of variables your dataframe contain. Alternatively, you hover your mouse over the head of the table, it will give you basic information about the variable type of the column. There are also other packages that offer data summer like the describe(), similar to summary(), and contents(), similar to str() in the Hmisc package. summary(all) str(all) library(Hmisc) describe(all) contents(all) "],
["tidy-your-data.html", "Chapter 5 Tidy your data 5.1 what is tidy data? 5.2 Tools in tidyr", " Chapter 5 Tidy your data 5.1 what is tidy data? Three rules: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. library(tidyverse) library(knitr) # tidy data kable(table1, caption = &quot;a This is a tidy dataset!&quot;) Table 5.1: a This is a tidy dataset! country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 kable(table2, caption = &quot;b case and population missing&quot;) Table 5.1: b case and population missing country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 kable(table3, caption = &quot;c case and population merged&quot;) Table 5.1: c case and population merged country year rate Afghanistan 1999 745/19987071 Afghanistan 2000 2666/20595360 Brazil 1999 37737/172006362 Brazil 2000 80488/174504898 China 1999 212258/1272915272 China 2000 213766/1280428583 kable(table4a, caption = &quot;d year missing, cases&quot;) Table 5.1: d year missing, cases country 1999 2000 Afghanistan 745 2666 Brazil 37737 80488 China 212258 213766 kable(table4b, caption = &quot;e year missing, population&quot;) Table 5.1: e year missing, population country 1999 2000 Afghanistan 19987071 20595360 Brazil 172006362 174504898 China 1272915272 1280428583 5.2 Tools in tidyr 5.2.1 gather() For some datasets, some of the column names are not names of variables but values of a variable. kable(table4a, caption= &quot;year missing, cases&quot;) Table 5.2: year missing, cases country 1999 2000 Afghanistan 745 2666 Brazil 37737 80488 China 212258 213766 We need to gat her years like 1999 and 2000 into one variable year. gather(table4a, &#39;1999&#39;,&#39;2000&#39;,key = &quot;year&quot;, value = &quot;cases&quot;) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 gather(table4b, &#39;1999&#39;,&#39;2000&#39;,key = &quot;year&quot;, value = &quot;population&quot;) ## # A tibble: 6 x 3 ## country year population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 19987071 ## 2 Brazil 1999 172006362 ## 3 China 1999 1272915272 ## 4 Afghanistan 2000 20595360 ## 5 Brazil 2000 174504898 ## 6 China 2000 1280428583 5.2.2 spread() Sometime the observations are scattered across muiltiple rows. kable(table2, caption = &quot;b case and population missing&quot;) Table 5.3: b case and population missing country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 spread(table2, key = type, value = count) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 To sum up, gather() makes wide tables long while spread() make long tables wide. The key idea here is to think about the variable you want to explore and make sure that they are place in different columns. 5.2.3 separate() In some cases, one column may contain a combination of two variables. We need to separate these two variables. kable(table3, caption = &quot;c case and population merged&quot;) Table 5.4: c case and population merged country year rate Afghanistan 1999 745/19987071 Afghanistan 2000 2666/20595360 Brazil 1999 37737/172006362 Brazil 2000 80488/174504898 China 1999 212258/1272915272 China 2000 213766/1280428583 #separate by a delimiter separate(table3, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 #separate by the first two digits separate(table3, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = 2) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 74 5/19987071 ## 2 Afghanistan 2000 26 66/20595360 ## 3 Brazil 1999 37 737/172006362 ## 4 Brazil 2000 80 488/174504898 ## 5 China 1999 21 2258/1272915272 ## 6 China 2000 21 3766/1280428583 #separate by the last two digits separate(table3, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = -2) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/199870 71 ## 2 Afghanistan 2000 2666/205953 60 ## 3 Brazil 1999 37737/1720063 62 ## 4 Brazil 2000 80488/1745048 98 ## 5 China 1999 212258/12729152 72 ## 6 China 2000 213766/12804285 83 5.2.4 unite() table_new = separate(table3, year, into = c(&quot;year1&quot;, &quot;year2&quot;), sep = 2) unite(table_new, new, year1, year2) ## # A tibble: 6 x 3 ## country new rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19_99 745/19987071 ## 2 Afghanistan 20_00 2666/20595360 ## 3 Brazil 19_99 37737/172006362 ## 4 Brazil 20_00 80488/174504898 ## 5 China 19_99 212258/1272915272 ## 6 China 20_00 213766/1280428583 # by default there is an underscore between two parts. unite(table_new, new, year1, year2, sep = &quot;&quot;) ## # A tibble: 6 x 3 ## country new rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 "],
["tranform-your-data.html", "Chapter 6 Tranform your data 6.1 Selecting variables of interest 6.2 Filtering observations 6.3 changing the order of rows 6.4 Generating new variables 6.5 the pipeline “%&gt;%” 6.6 Summarizing", " Chapter 6 Tranform your data 6.1 Selecting variables of interest When we get a dataset, one of the most important things to do is to pick the variables we need, especially when the raw dataset has too many columns. library(tidyverse) # getting the data filename = list.files(paste0(getwd(), &quot;/data&quot;),full.names=T, pattern = &quot;.csv&quot;) # get only csv files df = data.frame() bin = data.frame() for (i in 1:length(filename)){ # length(filename) = how many files bin = read.csv(filename[i]) df = rbind(df, bin) } #head(df) #colnames(df) In this dataset df, we need to get the ID of participants as stored in Subject, the stimuli they hear under the column name “tone.Trial”, their response “insex1.RESP”, their response time in “insex1.RT”, and the experiment conditions in “Procedure.Block.”. df_new = select(df, subject = &quot;Subject&quot;, stimuli = &quot;tone.Trial.&quot;, response = &quot;insex1.RESP&quot;, response_rt = &quot;insex1.RT&quot;, block = &quot;Procedure.Block.&quot;, ExperimentName) head(df_new) ## subject stimuli response response_rt block ExperimentName ## 1 402 NA NA pracproc Assim_main_chinese_500ms ## 2 402 NA NA pracproc Assim_main_chinese_500ms ## 3 402 NA NA pracproc Assim_main_chinese_500ms ## 4 402 NA NA pracproc Assim_main_chinese_500ms ## 5 402 NA NA pracproc Assim_main_chinese_500ms ## 6 402 NA NA pracproc Assim_main_chinese_500ms # select by names head(select(df_new, subject: response)) ## subject stimuli response ## 1 402 NA ## 2 402 NA ## 3 402 NA ## 4 402 NA ## 5 402 NA ## 6 402 NA head(select(df_new, subject: response)) ## subject stimuli response ## 1 402 NA ## 2 402 NA ## 3 402 NA ## 4 402 NA ## 5 402 NA ## 6 402 NA head(select(df_new, 1: 3)) ## subject stimuli response ## 1 402 NA ## 2 402 NA ## 3 402 NA ## 4 402 NA ## 5 402 NA ## 6 402 NA head(select(df_new, -subject)) ## stimuli response response_rt block ExperimentName ## 1 NA NA pracproc Assim_main_chinese_500ms ## 2 NA NA pracproc Assim_main_chinese_500ms ## 3 NA NA pracproc Assim_main_chinese_500ms ## 4 NA NA pracproc Assim_main_chinese_500ms ## 5 NA NA pracproc Assim_main_chinese_500ms ## 6 NA NA pracproc Assim_main_chinese_500ms head(select(df_new, ExperimentName, everything())) ## ExperimentName subject stimuli response response_rt block ## 1 Assim_main_chinese_500ms 402 NA NA pracproc ## 2 Assim_main_chinese_500ms 402 NA NA pracproc ## 3 Assim_main_chinese_500ms 402 NA NA pracproc ## 4 Assim_main_chinese_500ms 402 NA NA pracproc ## 5 Assim_main_chinese_500ms 402 NA NA pracproc ## 6 Assim_main_chinese_500ms 402 NA NA pracproc # change column names head(rename(df_new, exp = ExperimentName)) ## subject stimuli response response_rt block exp ## 1 402 NA NA pracproc Assim_main_chinese_500ms ## 2 402 NA NA pracproc Assim_main_chinese_500ms ## 3 402 NA NA pracproc Assim_main_chinese_500ms ## 4 402 NA NA pracproc Assim_main_chinese_500ms ## 5 402 NA NA pracproc Assim_main_chinese_500ms ## 6 402 NA NA pracproc Assim_main_chinese_500ms 6.2 Filtering observations Not all the data in the raw dataset are useful. We can use filter() function to select rows or observation based on some criteria. Three useful logical operators for forming conditions: &amp; means “and” | means “or” ! means “not” # removing data from the practice block df_new = filter(df_new, block != &quot;pracproc&quot;) head(df_new) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 45 0 block6 Assim_main_chinese_500ms ## 4 402 21 0 block6 Assim_main_chinese_500ms ## 5 402 33 f 1041 block6 Assim_main_chinese_500ms ## 6 402 241 0 block6 Assim_main_chinese_500ms # removing missing data in response column df_new = filter(df_new, !is.na(response)) df_new = filter(df_new, response != &quot;&quot;) head(df_new) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms ## 4 402 315 j 363 block6 Assim_main_chinese_500ms ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms ## 6 402 45 j 322 block6 Assim_main_chinese_500ms # pick up stimuli 33 and 21 head(filter(df_new, stimuli == 33 | stimuli == 21)) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 33 f 1041 block6 Assim_main_chinese_500ms ## 3 402 21 f 1234 block6 Assim_main_chinese_500ms ## 4 402 33 f 150 block6 Assim_main_chinese_500ms ## 5 402 33 f 206 block6 Assim_main_chinese_500ms ## 6 402 21 f 52 block6 Assim_main_chinese_500ms head(filter(df_new, stimuli %in% c(33, 21))) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 33 f 1041 block6 Assim_main_chinese_500ms ## 3 402 21 f 1234 block6 Assim_main_chinese_500ms ## 4 402 33 f 150 block6 Assim_main_chinese_500ms ## 5 402 33 f 206 block6 Assim_main_chinese_500ms ## 6 402 21 f 52 block6 Assim_main_chinese_500ms # removing data with respones time shorter than 200 head(filter(df_new, response_rt &lt; 200)) ## subject stimuli response response_rt block ExperimentName ## 1 402 45 j 109 block6 Assim_main_chinese_500ms ## 2 402 33 f 150 block6 Assim_main_chinese_500ms ## 3 402 21 f 52 block6 Assim_main_chinese_500ms ## 4 402 33 f 107 block5 Assim_main_chinese_500ms ## 5 402 33 f 153 block5 Assim_main_chinese_500ms ## 6 402 21 f 95 block2 Assim_main_chinese_500ms head(filter(df_new, response_rt &gt; 200)) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms ## 4 402 315 j 363 block6 Assim_main_chinese_500ms ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms ## 6 402 45 j 322 block6 Assim_main_chinese_500ms 6.3 changing the order of rows # arrange the dataframe by stimuli and response_rt columns head(arrange(df_new, stimuli, response_rt)) ## subject stimuli response response_rt block ExperimentName ## 1 418 21 g 6 block7 assim_main_vietnamese_500ms ## 2 418 21 g 51 block4 assim_main_vietnamese_500ms ## 3 402 21 f 52 block6 Assim_main_chinese_500ms ## 4 418 21 g 85 block1 assim_main_vietnamese_500ms ## 5 402 21 f 95 block2 Assim_main_chinese_500ms ## 6 418 21 g 99 block7 assim_main_vietnamese_500ms # arrange the dataframe by stimuli and the descending order of block columns head(arrange(df_new, stimuli, desc(block))) ## subject stimuli response response_rt block ExperimentName ## 1 402 21 f 609 block7 Assim_main_chinese_500ms ## 2 402 21 f 224 block7 Assim_main_chinese_500ms ## 3 402 21 f 286 block7 Assim_main_chinese_500ms ## 4 402 21 f 1136 block7 Assim_main_chinese_500ms ## 5 418 21 g 6 block7 assim_main_vietnamese_500ms ## 6 418 21 g 331 block7 assim_main_vietnamese_500ms 6.4 Generating new variables We can generate new variable based on existing variables using the function mutate() and transmutate(). The difference is mutate will keep the original variables while transmutate will erase orginal variables. # you can add, minus, log transform any numberic column head(mutate(df_new, response_rt_new = log(response_rt))) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms ## 4 402 315 j 363 block6 Assim_main_chinese_500ms ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms ## 6 402 45 j 322 block6 Assim_main_chinese_500ms ## response_rt_new ## 1 6.510258 ## 2 7.948385 ## 3 6.947937 ## 4 5.894403 ## 5 7.118016 ## 6 5.774552 # you can extract part of the information from a character variable head(mutate(df_new, ISI = str_extract(ExperimentName, &quot;2000|500&quot;))) ## subject stimuli response response_rt block ExperimentName ISI ## 1 402 33 f 672 block6 Assim_main_chinese_500ms 500 ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms 500 ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms 500 ## 4 402 315 j 363 block6 Assim_main_chinese_500ms 500 ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms 500 ## 6 402 45 j 322 block6 Assim_main_chinese_500ms 500 head(transmute(df_new, ISI = str_extract(ExperimentName, &quot;2000|500&quot;))) ## ISI ## 1 500 ## 2 500 ## 3 500 ## 4 500 ## 5 500 ## 6 500 # you can paste two variabls together head(transmute(df_new, ISI = paste(stimuli, block, sep = &quot;_&quot;))) ## ISI ## 1 33_block6 ## 2 315_block6 ## 3 33_block6 ## 4 315_block6 ## 5 21_block6 ## 6 45_block6 # you can recode a variable head( mutate(df_new, block = recode(block, block1 = &quot;ss&quot;, block2 = &quot;ss&quot;, block3 = &quot;sd&quot;, block4 = &quot;sd&quot;, block5 = &quot;ds&quot;, block6 = &quot;ds&quot;, block7 = &quot;dd&quot;))) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 ds Assim_main_chinese_500ms ## 2 402 315 j 2831 ds Assim_main_chinese_500ms ## 3 402 33 f 1041 ds Assim_main_chinese_500ms ## 4 402 315 j 363 ds Assim_main_chinese_500ms ## 5 402 21 f 1234 ds Assim_main_chinese_500ms ## 6 402 45 j 322 ds Assim_main_chinese_500ms 6.5 the pipeline “%&gt;%” You may have noticed the repetition in the above codes. We have to specify the dataframe every time we use a function and have to store it in a new name if we want to keep the original dataframe. Using pipeline %&gt;% can reduce the redundancy and the mistake we may make when we have a dozen of dataframes. df_final = df %&gt;% select(., subject = &quot;Subject&quot;, stimuli = &quot;tone.Trial.&quot;, response = &quot;insex1.RESP&quot;, response_rt = &quot;insex1.RT&quot;, block = &quot;Procedure.Block.&quot;, exp = ExperimentName)%&gt;% filter(block != &quot;pracproc&quot; &amp; !is.na(response) &amp; response != &quot;&quot;)%&gt;% mutate(ISI = str_extract(exp, &quot;2000|500&quot;), block = recode(block, block1 = &quot;ss&quot;, block2 = &quot;ss&quot;, block3 = &quot;sd&quot;, block4 = &quot;sd&quot;, block5 = &quot;ds&quot;, block6 = &quot;ds&quot;, block7 = &quot;dd&quot;)) 6.6 Summarizing Summarize() and group_by () are often used together to give us some basic summary of the data. df_final%&gt;% group_by(subject)%&gt;% summarize(count = n()) ## # A tibble: 2 x 2 ## subject count ## &lt;int&gt; &lt;int&gt; ## 1 402 221 ## 2 418 139 df_final%&gt;% group_by(subject, stimuli)%&gt;% summarize(rt = mean(response_rt)) ## # A tibble: 10 x 3 ## # Groups: subject [2] ## subject stimuli rt ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 402 21 747. ## 2 402 33 688. ## 3 402 45 831. ## 4 402 241 747. ## 5 402 315 787. ## 6 418 21 578. ## 7 418 33 553. ## 8 418 45 574. ## 9 418 241 715. ## 10 418 315 694. df_final%&gt;% group_by(stimuli, response)%&gt;% mutate(counter = 1)%&gt;% summarize(count = sum(counter))%&gt;% spread(stimuli, value = count) ## # A tibble: 5 x 6 ## response `21` `33` `45` `241` `315` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 f 24 21 1 12 NA ## 2 j NA NA 42 1 15 ## 3 d 1 11 NA 49 NA ## 4 g 54 45 NA 6 NA ## 5 h NA NA 23 NA 55 df_final%&gt;% group_by(stimuli,response)%&gt;% mutate(counter = 1)%&gt;% summarize(counter = sum(counter))%&gt;% mutate( percentage = counter/sum(counter), sum = sum(counter)) ## # A tibble: 15 x 5 ## # Groups: stimuli [5] ## stimuli response counter percentage sum ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 f 24 0.304 79 ## 2 21 d 1 0.0127 79 ## 3 21 g 54 0.684 79 ## 4 33 f 21 0.273 77 ## 5 33 d 11 0.143 77 ## 6 33 g 45 0.584 77 ## 7 45 f 1 0.0152 66 ## 8 45 j 42 0.636 66 ## 9 45 h 23 0.348 66 ## 10 241 f 12 0.176 68 ## 11 241 j 1 0.0147 68 ## 12 241 d 49 0.721 68 ## 13 241 g 6 0.0882 68 ## 14 315 j 15 0.214 70 ## 15 315 h 55 0.786 70 table.final = df_final%&gt;% group_by(stimuli,response)%&gt;% mutate(counter = 1)%&gt;% summarize(counter = sum(counter))%&gt;% mutate( percentage = counter/sum(counter), sum = sum(counter))%&gt;% select(stimuli,percentage, response)%&gt;% spread(stimuli, value = round(percentage, 2)) library(knitr) kable(table.final, caption = &quot;Percentage of choice&quot;) Table 6.1: Percentage of choice response 21 33 45 241 315 f 0.3037975 0.2727273 0.0151515 0.1764706 NA j NA NA 0.6363636 0.0147059 0.2142857 d 0.0126582 0.1428571 NA 0.7205882 NA g 0.6835443 0.5844156 NA 0.0882353 NA h NA NA 0.3484848 NA 0.7857143 "],
["build-your-own-function.html", "Chapter 7 Build your own function", " Chapter 7 Build your own function function_name = function(input){ do thing 1 do thing 2 return(output) } "],
["resources.html", "Chapter 8 Resources", " Chapter 8 Resources "]
]
