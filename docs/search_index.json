[
["index.html", "An Introduction to Data wrangling with R Chapter 1 Prerequisites 1.1 Installing R and R studio 1.2 Installing libraries in R 1.3 Install packages and library packages 1.4 Data and workbook 1.5 Schedule", " An Introduction to Data wrangling with R Juqiang Chen 2019-11-03 Chapter 1 Prerequisites This document is to accompany An introduction to data wrangling with R tutorial for DH Downunder 2019 at the University of Newcastle, Australia, from 9-13 December. I am a speech scientist working on cross-language lexical tone perception and production. I have rich experience dealing with experimental data and I am keen to help others with data wrangling, data visualization and statistical modelling problems. I aspire to promote a streamlined workflow with R packages to improve data analysis efficiency in quantitative analysis in the field of social science and linguistics. If you have any questions about the tutorial, please e-mail me at: j.chen2@westernsydney.edu.au Good data are somewhat alike but messy data are messy in different ways. This workshop aims to walk the audience through a streamlined workflow of data wrangling (importing data, cleaning data, transforming data) using popular R packages, such as dplyr and tidyr. It involves an introduction to basic concepts in data analysis, such as variables vs. observations, categorical vs. continuous variables, long vs. wide data. In addition, participants will learn how to (batch) import datasets, select and rename rows and columns, deal with missing data, generate new columns by computing the existing ones, and combine data frames. The pipe operator will be introduced to improve the efficiency and clarity of coding. Participants will also learn to write their own functions for data wrangling. Exercises and challenges involve real life research problems. Preliminary experience with R will be helpful, though not required. Participants are required to download and install R and R studio before the workshop. Datasets for the workshop are available online before the workshop. Participants are welcomed to bring their own data and apply what they learn on the spot. Before we start our journey of data wrangling with R, you will need to install R on your laptop. R is multi-platform, which means you can install R on your PC or MAC. 1.1 Installing R and R studio Use this link [https://cloud.r-project.org/] to download R and select the proper version for your laptop. knitr::include_graphics(&quot;img/installr.jpg&quot;) Figure 1.1: Download R 1.2 Installing libraries in R RStudio is an integrated development environment, or IDE, for R programming. Download and install it from [http://www.rstudio.com/download.] The free version is poweful enough. 1.3 Install packages and library packages install.packages(“package_name”) library(package_name) 1.4 Data and workbook Please download the data and workbook with this link. https://drive.google.com/open?id=18xwfD7f-eekQ60W-2IZ2wBkCX2GL08_u 1.5 Schedule Session 1 chapter 1 &amp; 2 Session 2 chapter 3, 4 &amp; 5 Session 3 chapter 3, 4 &amp; 5 "],
["intro.html", "Chapter 2 Basic data structures in R 2.1 Nominal, ordinal, interval/ratio variables 2.2 1D data structure: vectors 2.3 2D data structures: matrice and data frames 2.4 summary", " Chapter 2 Basic data structures in R Before we get our hands dirty in doing actual data analysis, it is desirable to first think about what types of variables and data structures we are dealing with. Before we talk about data structures in R, let’s first think about how data can be categorized. 2.1 Nominal, ordinal, interval/ratio variables Nominal variables are the data whose levels are labels or descriptions, which cannot be ordered. (e.g. sex, school, or nationality). They are categorical in nature. Ordinal variables can be ordered, or ranked in logical order, but the interval between levels of the variables are unknown. For example, when doing a survey, participants will be asked to rate. The subjective measurements of this kind are often ordinal variables. E.g. a Likert ranking scale; level of education (“&lt; high school”, “high school”, “associate’s degree”). We can assign numbers to levels of an ordinal variable, and can order them, but we should bear in mind that these variable are not numeric. For example, “strongly agree” and “neutral” cannot average out to an “agree.”, even though you can assign 5 to “strong agree” and 3 to “neutral”. Interval/ratio variables are measured or counted values: age, height, weight or number of students. The interval between numbers is equal: the interval between 1 kg and 2 kg is the same as between 3 kg and 4 kg. Interval/ratio variables can be discrete values, such as population (1332) or counts of items, or they can be continuous variables values that can take on any value within an interval, and can be expressed as decimals (1.009 kg). The variable type will determine (1) statistical analysis; (2) the way we summarize data with statistics and plots. We will be elaborating on this in the Explorative Data Analysis course. Variables can be stored in R in different data types. Normial and ordinal variables can be stored as character or factors (with levels). Interval data are stored as numbers either as integer or numeric (real or decimal). If you have only one variable, you can store it in a vector. However, more often than not, you have a bunch of variables that should be stored or imported as a matrix or data frame. 2.2 1D data structure: vectors A vector is a sequence of data elements of the same basic type: integer, double, logical or character. All elements of a vector must be the same type. 2.2.1 Creating vectors a = 8:17 b &lt;- c(9, 10, 100, 38) c = c (TRUE, FALSE, TRUE, FALSE) c = c (T, F, T, F) d = c (&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;FALSE&quot;) # You can change the type of a vector with as.vector function. as.vector(b, mode = &quot;character&quot;) ## [1] &quot;9&quot; &quot;10&quot; &quot;100&quot; &quot;38&quot; # When you put elements of different types in one vector, R will automatically change the type of some elements to keep the whole vector homogenous. e = c(9,10, &quot;ab&quot;, &quot;cd&quot;) f = c(10, 11, T, F) c () is a function in R. There are some other basic functions in R that you can play with to generate vectors. A = 9:20 + 1 B = seq (1, 10) C = seq (1, 20, by= 2) D = rep (5, 4) E = rep (c(1,2,3), 4) G = rep (c(1,2,3), each = 4) # Now that you have a vector, you can do some Maths. max(a) ## [1] 17 min(a) ## [1] 8 range(a) ## [1] 8 17 sum(a) ## [1] 125 mean(a) ## [1] 12.5 median(a) ## [1] 12.5 quantile(a) ## 0% 25% 50% 75% 100% ## 8.00 10.25 12.50 14.75 17.00 sd(a) ## [1] 3.02765 round(sd(a), 2) ## [1] 3.03 2.2.2 creating list objects We can put vectors of different types (e.g., number, logic or character) and lengths in a list object. list1 = list(a, b, c, d, e, f) list1 ## [[1]] ## [1] 8 9 10 11 12 13 14 15 16 17 ## ## [[2]] ## [1] 9 10 100 38 ## ## [[3]] ## [1] TRUE FALSE TRUE FALSE ## ## [[4]] ## [1] &quot;TRUE&quot; &quot;FALSE&quot; &quot;FALSE&quot; ## ## [[5]] ## [1] &quot;9&quot; &quot;10&quot; &quot;ab&quot; &quot;cd&quot; ## ## [[6]] ## [1] 10 11 1 0 # More often than not, we do not make list ourselves but have to deal with lists when we get outputs from stats models. 2.3 2D data structures: matrice and data frames Most of us have had some experience with the Excel spreadsheet. Data in a spreadsheet are arranged by rows and columns in a rectangular space. This is a typical 2 dimensional data structure. In R, we can have two ways of forming tabular data like a spreadsheet: the matrix and dataframe. A matrix is a collection of data elements arranged in a two-dimensional rectangular layout in which all the elements must be of the same type (e.g., numeric or character). Dataframe is similar to matrix in shape but only differs in that different types of data can co-exist in different columns. Thus, in data analysis, we use dataframes more often than matrix. # Let&#39;s generate a dataframe from scratch. id = seq(1, 40) gender = rep(c(&quot;male&quot;, &quot;female&quot;), 5) maths = rnorm(40, mean = 70, sd = 5) english = rnorm(40, mean = 80, sd = 9) music = rnorm(40, mean = 75, sd = 10) pe = rnorm(40, mean = 86, sd = 12) df1 = data.frame (id, gender, maths, english) Now let’s explore the data frame we just created. str(df1) ## &#39;data.frame&#39;: 40 obs. of 4 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ gender : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 2 1 2 1 2 1 ... ## $ maths : num 70.6 66 76.6 67.9 75.4 ... ## $ english: num 96.2 82.9 78.9 97.5 79 ... summary(df1) ## id gender maths english ## Min. : 1.00 female:20 Min. :58.02 Min. :54.10 ## 1st Qu.:10.75 male :20 1st Qu.:65.84 1st Qu.:74.28 ## Median :20.50 Median :68.99 Median :79.14 ## Mean :20.50 Mean :69.46 Mean :81.22 ## 3rd Qu.:30.25 3rd Qu.:73.44 3rd Qu.:89.45 ## Max. :40.00 Max. :83.97 Max. :98.35 nrow(df1) ## [1] 40 ncol(df1) ## [1] 4 attributes(df1) ## $names ## [1] &quot;id&quot; &quot;gender&quot; &quot;maths&quot; &quot;english&quot; ## ## $class ## [1] &quot;data.frame&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ## [24] 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 2.3.1 what if I want to change column names or add variable to the df? df2 = data.frame (id = id, gender = gender, maths = maths, english = english) df2 = cbind(df2, pe) colnames(df2) = c(&quot;ID&quot;, &quot;SEX&quot;,&quot;MATHS&quot;,&quot;ENGLISH&quot;,&quot;PE&quot;) head(df2) ## ID SEX MATHS ENGLISH PE ## 1 1 male 70.60786 96.18738 106.21940 ## 2 2 female 66.02075 82.88808 99.22090 ## 3 3 male 76.61313 78.92087 90.57023 ## 4 4 female 67.86063 97.50577 94.22734 ## 5 5 male 75.35260 78.95446 86.48396 ## 6 6 female 64.57531 70.02403 86.61844 2.3.2 Subsetting dataframes We all know how to select part of an Excel spreadsheet by clicking and moving our mouse. In R, when we want to select part of a dataframe, we use this formula, dataframe[row, column]. There are various ways we can use this formula and believe it or not, you will love them! # the complete dataset df2 ## ID SEX MATHS ENGLISH PE ## 1 1 male 70.60786 96.18738 106.21940 ## 2 2 female 66.02075 82.88808 99.22090 ## 3 3 male 76.61313 78.92087 90.57023 ## 4 4 female 67.86063 97.50577 94.22734 ## 5 5 male 75.35260 78.95446 86.48396 ## 6 6 female 64.57531 70.02403 86.61844 ## 7 7 male 58.02073 79.03896 95.60216 ## 8 8 female 75.30031 73.05779 106.03506 ## 9 9 male 68.22077 91.74031 84.64802 ## 10 10 female 76.02277 78.36353 72.87812 ## 11 11 male 67.55812 94.57711 78.98259 ## 12 12 female 71.87510 83.35954 88.78212 ## 13 13 male 74.10696 82.50176 106.31110 ## 14 14 female 68.52183 75.30506 112.03028 ## 15 15 male 65.38309 72.12042 94.73101 ## 16 16 female 74.23505 74.67351 100.82819 ## 17 17 male 63.74529 78.88007 91.63817 ## 18 18 female 72.18371 74.09697 72.70249 ## 19 19 male 59.86169 98.35468 94.08341 ## 20 20 female 83.97191 70.35074 71.98943 ## 21 21 male 67.52351 94.21585 70.21307 ## 22 22 female 77.51363 82.15348 110.26140 ## 23 23 male 70.50719 85.22256 101.21087 ## 24 24 female 70.06098 71.74142 59.15373 ## 25 25 male 73.73767 75.88835 112.09462 ## 26 26 female 64.38211 79.24899 85.15776 ## 27 27 male 73.34523 91.72959 88.98591 ## 28 28 female 69.75343 81.78931 95.52651 ## 29 29 male 74.21133 54.10286 93.13769 ## 30 30 female 69.45415 89.07405 89.21665 ## 31 31 male 64.56264 74.34450 91.40643 ## 32 32 female 72.85040 81.49179 114.34594 ## 33 33 male 64.51821 90.57953 87.45215 ## 34 34 female 65.98878 73.69075 68.51921 ## 35 35 male 66.73775 68.94751 92.95056 ## 36 36 female 67.18622 73.07936 89.34898 ## 37 37 male 71.11416 97.84107 95.59139 ## 38 38 female 64.02525 85.38702 66.24643 ## 39 39 male 63.54045 76.27456 85.89829 ## 40 40 female 67.37267 91.21655 90.35612 df2[2:5, ] # from row 2 to row 5 ## ID SEX MATHS ENGLISH PE ## 2 2 female 66.02075 82.88808 99.22090 ## 3 3 male 76.61313 78.92087 90.57023 ## 4 4 female 67.86063 97.50577 94.22734 ## 5 5 male 75.35260 78.95446 86.48396 df2[ , 1:2] # select column 1 to 2 ## ID SEX ## 1 1 male ## 2 2 female ## 3 3 male ## 4 4 female ## 5 5 male ## 6 6 female ## 7 7 male ## 8 8 female ## 9 9 male ## 10 10 female ## 11 11 male ## 12 12 female ## 13 13 male ## 14 14 female ## 15 15 male ## 16 16 female ## 17 17 male ## 18 18 female ## 19 19 male ## 20 20 female ## 21 21 male ## 22 22 female ## 23 23 male ## 24 24 female ## 25 25 male ## 26 26 female ## 27 27 male ## 28 28 female ## 29 29 male ## 30 30 female ## 31 31 male ## 32 32 female ## 33 33 male ## 34 34 female ## 35 35 male ## 36 36 female ## 37 37 male ## 38 38 female ## 39 39 male ## 40 40 female df2[ , c(&quot;ENGLISH&quot;, &quot;PE&quot;)] # select by column names ## ENGLISH PE ## 1 96.18738 106.21940 ## 2 82.88808 99.22090 ## 3 78.92087 90.57023 ## 4 97.50577 94.22734 ## 5 78.95446 86.48396 ## 6 70.02403 86.61844 ## 7 79.03896 95.60216 ## 8 73.05779 106.03506 ## 9 91.74031 84.64802 ## 10 78.36353 72.87812 ## 11 94.57711 78.98259 ## 12 83.35954 88.78212 ## 13 82.50176 106.31110 ## 14 75.30506 112.03028 ## 15 72.12042 94.73101 ## 16 74.67351 100.82819 ## 17 78.88007 91.63817 ## 18 74.09697 72.70249 ## 19 98.35468 94.08341 ## 20 70.35074 71.98943 ## 21 94.21585 70.21307 ## 22 82.15348 110.26140 ## 23 85.22256 101.21087 ## 24 71.74142 59.15373 ## 25 75.88835 112.09462 ## 26 79.24899 85.15776 ## 27 91.72959 88.98591 ## 28 81.78931 95.52651 ## 29 54.10286 93.13769 ## 30 89.07405 89.21665 ## 31 74.34450 91.40643 ## 32 81.49179 114.34594 ## 33 90.57953 87.45215 ## 34 73.69075 68.51921 ## 35 68.94751 92.95056 ## 36 73.07936 89.34898 ## 37 97.84107 95.59139 ## 38 85.38702 66.24643 ## 39 76.27456 85.89829 ## 40 91.21655 90.35612 df2[c(1,2,3), ] #select the first three rows ## ID SEX MATHS ENGLISH PE ## 1 1 male 70.60786 96.18738 106.21940 ## 2 2 female 66.02075 82.88808 99.22090 ## 3 3 male 76.61313 78.92087 90.57023 df2[seq(1, 40, 2), ] #select every other rows from 1 to 40 rows ## ID SEX MATHS ENGLISH PE ## 1 1 male 70.60786 96.18738 106.21940 ## 3 3 male 76.61313 78.92087 90.57023 ## 5 5 male 75.35260 78.95446 86.48396 ## 7 7 male 58.02073 79.03896 95.60216 ## 9 9 male 68.22077 91.74031 84.64802 ## 11 11 male 67.55812 94.57711 78.98259 ## 13 13 male 74.10696 82.50176 106.31110 ## 15 15 male 65.38309 72.12042 94.73101 ## 17 17 male 63.74529 78.88007 91.63817 ## 19 19 male 59.86169 98.35468 94.08341 ## 21 21 male 67.52351 94.21585 70.21307 ## 23 23 male 70.50719 85.22256 101.21087 ## 25 25 male 73.73767 75.88835 112.09462 ## 27 27 male 73.34523 91.72959 88.98591 ## 29 29 male 74.21133 54.10286 93.13769 ## 31 31 male 64.56264 74.34450 91.40643 ## 33 33 male 64.51821 90.57953 87.45215 ## 35 35 male 66.73775 68.94751 92.95056 ## 37 37 male 71.11416 97.84107 95.59139 ## 39 39 male 63.54045 76.27456 85.89829 2.4 summary Dimensions Homogenous Heterogeneous 1D Atomic Vector List 2D Matrix Data frame nD Array "],
["what-is-data-wrangling.html", "Chapter 3 What is data wrangling? 3.1 Data analysis workflow 3.2 Data wrangling", " Chapter 3 What is data wrangling? 3.1 Data analysis workflow A common workflow for data analysis involves importing data, cleaning data, transforming data, visualizing and modeling data for reports or papers. If you have not worked with R before, you may use excel to do data cleaning and do simple tranformation work with pivot tables and save the results in a new spreadsheet. You can also draw bar charts, pie charts and histrograms in the spreadsheet. One thing I feel annoying is that in order to keep a record of what you have done, you need to store a couple of sheets inside a workbook. Still, you can miss some steps and cannot recall you have done after a month. When you need to do more complex stats modeling like ANOVA or linear regression, you may import the spreadsheet into SPSS and other stats packages.But if the data are not arranged in the way as required by these packages, chances are that you will have to go back to Excel again. If you are lucky and you get all the analysis done. Usually at the end of the project, you will find a number of .xsl or .csv files in your data folder. You may name them with the analysis you do or the date you generate them. But after six months, you may feel unsure about what is in these files, not to mention, others who want to reuse it. But if you are using R, things can be easiler because each step in the data analysis is recorded and fully reproducible. knitr::include_graphics(&quot;img/DA_workflow.png&quot;) Figure 3.1: Data analysis workflow 3.2 Data wrangling Data wrangling (see the above figure in red box) involves some basic procedures (importing, tidying and transforming). R,and its packages, tidyverse in particular, provide a number of functions that can help us deal with data cleaning and tranformation. We will be learning how to use these functions in the follow sessions. "],
["import-your-data.html", "Chapter 4 Import your data 4.1 from CSV/TXT 4.2 from EXCEL 4.3 Batch import 4.4 Take a glimpse of the dataframe", " Chapter 4 Import your data 4.1 from CSV/TXT You can import data in csv (comma seperate) or text files that use a different delimiter to seperate data. There two groups of functions you can use: Base R functions readr package functions read.table( ) is a multipurpose function in R for importing data, and this function has two special cases: read.csv( ) and read.delim( ). read.csv( ) is a wrapper for read.table with some default settings: sep = “,” ; header = TRUE. read.delim( ) is a wrapper for read.table with some default settings: sep = “” ; header = TRUE. readr package functions you need to library(readr) readr functions are 10 times faster than built-in functions. read_csv( ): you can specify col_types = list(col_double(), col_character()) col_names = c(“a”,“b”) read_delim( ) read_table( ) However, I found R-studio Import Dataset function most useful when importing data. It offers an user interface and you will know how your data look like when you choose different settings. After R-studio inter face helps you import data initially, it is time for us to take a look at what happens in the console. You may want to copy the code automatically generated by R-Studio and paste it in your script. A little more about the path to directory: it is helpful to get to know your working directory, you can get this information by getwd( ). When you know where you are, you can specify your folder either relative to your present location or with the absolute path. participant_1 &lt;- read.csv(&quot;data/participant_1.csv&quot;) #stringAsFactor = FALSE participant_2 &lt;- read.csv(&quot;data/participant_2.csv&quot;) ## from TXT participant_1_tab &lt;- read.delim(&quot;~/OneDrive_Backup/OneDrive - Western Sydney University/JuqiangCHEN/310_Tutorial/DH_Data_wrangling/data/participant_1_tab.txt&quot;) 4.2 from EXCEL library(readxl) excel_test &lt;- read_excel(&quot;data/excel_test.xlsx&quot;, sheet = &quot;participant_1&quot;) 4.3 Batch import rbind(participant_1, participant_2) all = rbind(participant_1, participant_2) # what about 10 more people? participant_3 &lt;- read.csv(&quot;data/participant_3.csv&quot;) # get all the filenames of the folder getwd() # get working directory paste0(getwd(), &quot;/data&quot;) #specify the directory for the data list.files(paste0(getwd(), &quot;/data&quot;),full.names=T) # full.names=T means getting the full path filename = list.files(paste0(getwd(), &quot;/data&quot;),full.names=T, pattern = &quot;.csv&quot;) # get only csv files # now you need a loop df = data.frame() bin = data.frame() for (i in 1:length(filename)){ # length(filename) = how many files bin = read.csv(filename[i]) df = rbind(df, bin) } 4.4 Take a glimpse of the dataframe R has some basic functions that can help us have a quick look at the data frame that we import. summary( ) 1 For each factor variable, the levels are printed. 2 For each numeric variable, the minimun, first quantile, median, mean, third quantile and the maximun values are shown. str( ) structure This gives the information about the types of variables that your dataframe contain. Alternatively, you can hover your mouse over the head of the table, it will give you basic information about the variable type of the column. There are also other packages that offer data summer like the describe ( ), similar to summary ( ), and contents ( ), similar to str ( ) in the Hmisc package. summary(all) str(all) library(Hmisc) describe(all) contents(all) "],
["tidy-your-data.html", "Chapter 5 Tidy your data 5.1 what is tidy data? 5.2 Tools in tidyr", " Chapter 5 Tidy your data 5.1 what is tidy data? Three rules: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. library(tidyverse) library(knitr) # tidy data kable(table1, caption = &quot;a This is a tidy dataset!&quot;) Table 5.1: a This is a tidy dataset! country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 kable(table2, caption = &quot;b case and population missing&quot;) Table 5.1: b case and population missing country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 kable(table3, caption = &quot;c case and population merged&quot;) Table 5.1: c case and population merged country year rate Afghanistan 1999 745/19987071 Afghanistan 2000 2666/20595360 Brazil 1999 37737/172006362 Brazil 2000 80488/174504898 China 1999 212258/1272915272 China 2000 213766/1280428583 kable(table4a, caption = &quot;d year missing, cases&quot;) Table 5.1: d year missing, cases country 1999 2000 Afghanistan 745 2666 Brazil 37737 80488 China 212258 213766 kable(table4b, caption = &quot;e year missing, population&quot;) Table 5.1: e year missing, population country 1999 2000 Afghanistan 19987071 20595360 Brazil 172006362 174504898 China 1272915272 1280428583 5.2 Tools in tidyr 5.2.1 gather ( ) For some datasets, some of the column names are not names of variables but values of a variable. kable(table4a, caption= &quot;year missing, cases&quot;) Table 5.2: year missing, cases country 1999 2000 Afghanistan 745 2666 Brazil 37737 80488 China 212258 213766 We need to gather years like 1999 and 2000 into one variable year. gather(table4a, &#39;1999&#39;,&#39;2000&#39;,key = &quot;year&quot;, value = &quot;cases&quot;) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 gather(table4b, &#39;1999&#39;,&#39;2000&#39;,key = &quot;year&quot;, value = &quot;population&quot;) ## # A tibble: 6 x 3 ## country year population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 19987071 ## 2 Brazil 1999 172006362 ## 3 China 1999 1272915272 ## 4 Afghanistan 2000 20595360 ## 5 Brazil 2000 174504898 ## 6 China 2000 1280428583 5.2.2 spread ( ) Sometime the observations are scattered across muiltiple rows. kable(table2, caption = &quot;b case and population missing&quot;) Table 5.3: b case and population missing country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 spread(table2, key = type, value = count) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 To sum up, gather() makes wide tables long while spread() makes long tables wide. The key idea here is to think about the variables you want to explore and make sure that they are placed in different columns. This is very important for data visualization and stats modeling in R. 5.2.3 separate() In some cases, one column may contain a combination of two variables. We need to separate these two variables. kable(table3, caption = &quot;c case and population merged&quot;) Table 5.4: c case and population merged country year rate Afghanistan 1999 745/19987071 Afghanistan 2000 2666/20595360 Brazil 1999 37737/172006362 Brazil 2000 80488/174504898 China 1999 212258/1272915272 China 2000 213766/1280428583 #separate by a delimiter separate(table3, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 #separate by the first two digits separate(table3, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = 2) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 74 5/19987071 ## 2 Afghanistan 2000 26 66/20595360 ## 3 Brazil 1999 37 737/172006362 ## 4 Brazil 2000 80 488/174504898 ## 5 China 1999 21 2258/1272915272 ## 6 China 2000 21 3766/1280428583 #separate by the last two digits separate(table3, rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = -2) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/199870 71 ## 2 Afghanistan 2000 2666/205953 60 ## 3 Brazil 1999 37737/1720063 62 ## 4 Brazil 2000 80488/1745048 98 ## 5 China 1999 212258/12729152 72 ## 6 China 2000 213766/12804285 83 5.2.4 unite() table_new = separate(table3, year, into = c(&quot;year1&quot;, &quot;year2&quot;), sep = 2) table_new ## # A tibble: 6 x 4 ## country year1 year2 rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745/19987071 ## 2 Afghanistan 20 00 2666/20595360 ## 3 Brazil 19 99 37737/172006362 ## 4 Brazil 20 00 80488/174504898 ## 5 China 19 99 212258/1272915272 ## 6 China 20 00 213766/1280428583 unite(table_new, new, year1, year2)# by default there is an underscore between two parts. ## # A tibble: 6 x 3 ## country new rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19_99 745/19987071 ## 2 Afghanistan 20_00 2666/20595360 ## 3 Brazil 19_99 37737/172006362 ## 4 Brazil 20_00 80488/174504898 ## 5 China 19_99 212258/1272915272 ## 6 China 20_00 213766/1280428583 unite(table_new, new, year1, year2, sep = &quot;&quot;) ## # A tibble: 6 x 3 ## country new rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 "],
["tranform-your-data.html", "Chapter 6 Tranform your data 6.1 Selecting variables of interest 6.2 Filtering observations 6.3 Changing the order of rows 6.4 Generating new variables 6.5 The pipeline “%&gt;%” 6.6 Summarizing", " Chapter 6 Tranform your data 6.1 Selecting variables of interest When we get a dataset, one of the most important things to do is to pick the variables we need, especially when the raw dataset has too many columns. library(tidyverse) # getting the data filename = list.files(paste0(getwd(), &quot;/data&quot;),full.names=T, pattern = &quot;.csv&quot;) # get only csv files df = data.frame() bin = data.frame() for (i in 1:length(filename)){ # length(filename) = how many files bin = read.csv(filename[i]) df = rbind(df, bin) } #head(df) #colnames(df) In this dataset df, we need to get the ID of participants as stored in Subject, the stimuli they heard in “tone.Trial”, their response in “insex1.RESP”, their response time in “insex1.RT”, and the experiment conditions in “Procedure.Block.”. df_new = select(df, subject = &quot;Subject&quot;, stimuli = &quot;tone.Trial.&quot;, response = &quot;insex1.RESP&quot;, response_rt = &quot;insex1.RT&quot;, block = &quot;Procedure.Block.&quot;, ExperimentName) head(df_new) ## subject stimuli response response_rt block ExperimentName ## 1 402 NA NA pracproc Assim_main_chinese_500ms ## 2 402 NA NA pracproc Assim_main_chinese_500ms ## 3 402 NA NA pracproc Assim_main_chinese_500ms ## 4 402 NA NA pracproc Assim_main_chinese_500ms ## 5 402 NA NA pracproc Assim_main_chinese_500ms ## 6 402 NA NA pracproc Assim_main_chinese_500ms # select by names head(select(df_new, subject: response)) ## subject stimuli response ## 1 402 NA ## 2 402 NA ## 3 402 NA ## 4 402 NA ## 5 402 NA ## 6 402 NA head(select(df_new, subject: response)) ## subject stimuli response ## 1 402 NA ## 2 402 NA ## 3 402 NA ## 4 402 NA ## 5 402 NA ## 6 402 NA head(select(df_new, 1: 3)) ## subject stimuli response ## 1 402 NA ## 2 402 NA ## 3 402 NA ## 4 402 NA ## 5 402 NA ## 6 402 NA head(select(df_new, -subject)) ## stimuli response response_rt block ExperimentName ## 1 NA NA pracproc Assim_main_chinese_500ms ## 2 NA NA pracproc Assim_main_chinese_500ms ## 3 NA NA pracproc Assim_main_chinese_500ms ## 4 NA NA pracproc Assim_main_chinese_500ms ## 5 NA NA pracproc Assim_main_chinese_500ms ## 6 NA NA pracproc Assim_main_chinese_500ms head(select(df_new, ExperimentName, everything())) ## ExperimentName subject stimuli response response_rt block ## 1 Assim_main_chinese_500ms 402 NA NA pracproc ## 2 Assim_main_chinese_500ms 402 NA NA pracproc ## 3 Assim_main_chinese_500ms 402 NA NA pracproc ## 4 Assim_main_chinese_500ms 402 NA NA pracproc ## 5 Assim_main_chinese_500ms 402 NA NA pracproc ## 6 Assim_main_chinese_500ms 402 NA NA pracproc # change column names head(rename(df_new, exp = ExperimentName)) ## subject stimuli response response_rt block exp ## 1 402 NA NA pracproc Assim_main_chinese_500ms ## 2 402 NA NA pracproc Assim_main_chinese_500ms ## 3 402 NA NA pracproc Assim_main_chinese_500ms ## 4 402 NA NA pracproc Assim_main_chinese_500ms ## 5 402 NA NA pracproc Assim_main_chinese_500ms ## 6 402 NA NA pracproc Assim_main_chinese_500ms 6.2 Filtering observations Not all the data in the raw dataset are useful. We can use filter( ) function to select rows or observations based on some criteria. Three useful logical operators for forming conditions: &amp; means “and” | means “or” ! means “not” # removing data from the practice block df_new = filter(df_new, block != &quot;pracproc&quot;) head(df_new) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 45 0 block6 Assim_main_chinese_500ms ## 4 402 21 0 block6 Assim_main_chinese_500ms ## 5 402 33 f 1041 block6 Assim_main_chinese_500ms ## 6 402 241 0 block6 Assim_main_chinese_500ms # removing missing data in response column df_new = filter(df_new, !is.na(response)) df_new = filter(df_new, response != &quot;&quot;) head(df_new) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms ## 4 402 315 j 363 block6 Assim_main_chinese_500ms ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms ## 6 402 45 j 322 block6 Assim_main_chinese_500ms # pick up stimuli 33 and 21 head(filter(df_new, stimuli == 33 | stimuli == 21)) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 33 f 1041 block6 Assim_main_chinese_500ms ## 3 402 21 f 1234 block6 Assim_main_chinese_500ms ## 4 402 33 f 150 block6 Assim_main_chinese_500ms ## 5 402 33 f 206 block6 Assim_main_chinese_500ms ## 6 402 21 f 52 block6 Assim_main_chinese_500ms head(filter(df_new, stimuli %in% c(33, 21))) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 33 f 1041 block6 Assim_main_chinese_500ms ## 3 402 21 f 1234 block6 Assim_main_chinese_500ms ## 4 402 33 f 150 block6 Assim_main_chinese_500ms ## 5 402 33 f 206 block6 Assim_main_chinese_500ms ## 6 402 21 f 52 block6 Assim_main_chinese_500ms # removing data with respones time shorter than 200 head(filter(df_new, response_rt &lt; 200)) ## subject stimuli response response_rt block ExperimentName ## 1 402 45 j 109 block6 Assim_main_chinese_500ms ## 2 402 33 f 150 block6 Assim_main_chinese_500ms ## 3 402 21 f 52 block6 Assim_main_chinese_500ms ## 4 402 33 f 107 block5 Assim_main_chinese_500ms ## 5 402 33 f 153 block5 Assim_main_chinese_500ms ## 6 402 21 f 95 block2 Assim_main_chinese_500ms head(filter(df_new, response_rt &gt; 200)) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms ## 4 402 315 j 363 block6 Assim_main_chinese_500ms ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms ## 6 402 45 j 322 block6 Assim_main_chinese_500ms 6.3 Changing the order of rows # arrange the dataframe by stimuli and response_rt columns head(arrange(df_new, stimuli, response_rt)) ## subject stimuli response response_rt block ExperimentName ## 1 418 21 g 6 block7 assim_main_vietnamese_500ms ## 2 418 21 g 51 block4 assim_main_vietnamese_500ms ## 3 402 21 f 52 block6 Assim_main_chinese_500ms ## 4 418 21 g 85 block1 assim_main_vietnamese_500ms ## 5 402 21 f 95 block2 Assim_main_chinese_500ms ## 6 418 21 g 99 block7 assim_main_vietnamese_500ms # arrange the dataframe by stimuli and the descending order of block columns head(arrange(df_new, stimuli, desc(block))) ## subject stimuli response response_rt block ExperimentName ## 1 402 21 f 609 block7 Assim_main_chinese_500ms ## 2 402 21 f 224 block7 Assim_main_chinese_500ms ## 3 402 21 f 286 block7 Assim_main_chinese_500ms ## 4 402 21 f 1136 block7 Assim_main_chinese_500ms ## 5 418 21 g 6 block7 assim_main_vietnamese_500ms ## 6 418 21 g 331 block7 assim_main_vietnamese_500ms 6.4 Generating new variables We can generate new variables based on existing variables using the function mutate() and transmutate(). The difference is mutate will keep the original variables while transmutate will erase orginal variables. # you can add, minus, log transform any numberic column head(mutate(df_new, response_rt_new = log(response_rt))) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 block6 Assim_main_chinese_500ms ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms ## 4 402 315 j 363 block6 Assim_main_chinese_500ms ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms ## 6 402 45 j 322 block6 Assim_main_chinese_500ms ## response_rt_new ## 1 6.510258 ## 2 7.948385 ## 3 6.947937 ## 4 5.894403 ## 5 7.118016 ## 6 5.774552 # you can extract part of the information from a character variable head(mutate(df_new, ISI = str_extract(ExperimentName, &quot;2000|500&quot;))) ## subject stimuli response response_rt block ExperimentName ISI ## 1 402 33 f 672 block6 Assim_main_chinese_500ms 500 ## 2 402 315 j 2831 block6 Assim_main_chinese_500ms 500 ## 3 402 33 f 1041 block6 Assim_main_chinese_500ms 500 ## 4 402 315 j 363 block6 Assim_main_chinese_500ms 500 ## 5 402 21 f 1234 block6 Assim_main_chinese_500ms 500 ## 6 402 45 j 322 block6 Assim_main_chinese_500ms 500 head(transmute(df_new, ISI = str_extract(ExperimentName, &quot;2000|500&quot;))) ## ISI ## 1 500 ## 2 500 ## 3 500 ## 4 500 ## 5 500 ## 6 500 # you can paste two variabls together head(transmute(df_new, ISI = paste(stimuli, block, sep = &quot;_&quot;))) ## ISI ## 1 33_block6 ## 2 315_block6 ## 3 33_block6 ## 4 315_block6 ## 5 21_block6 ## 6 45_block6 # you can recode a variable head( mutate(df_new, block = recode(block, block1 = &quot;ss&quot;, block2 = &quot;ss&quot;, block3 = &quot;sd&quot;, block4 = &quot;sd&quot;, block5 = &quot;ds&quot;, block6 = &quot;ds&quot;, block7 = &quot;dd&quot;))) ## subject stimuli response response_rt block ExperimentName ## 1 402 33 f 672 ds Assim_main_chinese_500ms ## 2 402 315 j 2831 ds Assim_main_chinese_500ms ## 3 402 33 f 1041 ds Assim_main_chinese_500ms ## 4 402 315 j 363 ds Assim_main_chinese_500ms ## 5 402 21 f 1234 ds Assim_main_chinese_500ms ## 6 402 45 j 322 ds Assim_main_chinese_500ms 6.5 The pipeline “%&gt;%” You may have noticed the repetition in the above codes. We have to specify the dataframe every time we use a function and have to store it in a new name if we want to keep the original dataframe. Using pipeline %&gt;% can reduce the redundancy and the mistake we may make when we have a dozen of dataframes to refer to. df_final = df %&gt;% # selecting the columns we need select(., subject = &quot;Subject&quot;, stimuli = &quot;tone.Trial.&quot;, response = &quot;insex1.RESP&quot;, response_rt = &quot;insex1.RT&quot;, block = &quot;Procedure.Block.&quot;, exp = ExperimentName)%&gt;% #filtering out useless data filter(block != &quot;pracproc&quot; &amp; !is.na(response) &amp; response != &quot;&quot;)%&gt;% # generating new variables based on old variables mutate(ISI = str_extract(exp, &quot;2000|500&quot;), block = recode(block, block1 = &quot;ss&quot;, block2 = &quot;ss&quot;, block3 = &quot;sd&quot;, block4 = &quot;sd&quot;, block5 = &quot;ds&quot;, block6 = &quot;ds&quot;, block7 = &quot;dd&quot;)) 6.6 Summarizing Summarize() and group_by () are often used together to give us some basic summary of the data. df_final%&gt;% group_by(subject)%&gt;% summarize(count = n()) ## # A tibble: 2 x 2 ## subject count ## &lt;int&gt; &lt;int&gt; ## 1 402 221 ## 2 418 139 df_final%&gt;% group_by(subject, stimuli)%&gt;% summarize(rt = mean(response_rt)) ## # A tibble: 10 x 3 ## # Groups: subject [2] ## subject stimuli rt ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 402 21 747. ## 2 402 33 688. ## 3 402 45 831. ## 4 402 241 747. ## 5 402 315 787. ## 6 418 21 578. ## 7 418 33 553. ## 8 418 45 574. ## 9 418 241 715. ## 10 418 315 694. df_final%&gt;% group_by(stimuli, response)%&gt;% mutate(counter = 1)%&gt;% summarize(count = sum(counter))%&gt;% spread(stimuli, value = count) ## # A tibble: 5 x 6 ## response `21` `33` `45` `241` `315` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 f 24 21 1 12 NA ## 2 j NA NA 42 1 15 ## 3 d 1 11 NA 49 NA ## 4 g 54 45 NA 6 NA ## 5 h NA NA 23 NA 55 df_final%&gt;% group_by(stimuli,response)%&gt;% mutate(counter = 1)%&gt;% summarize(counter = sum(counter))%&gt;% mutate( percentage = counter/sum(counter), sum = sum(counter)) ## # A tibble: 15 x 5 ## # Groups: stimuli [5] ## stimuli response counter percentage sum ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 f 24 0.304 79 ## 2 21 d 1 0.0127 79 ## 3 21 g 54 0.684 79 ## 4 33 f 21 0.273 77 ## 5 33 d 11 0.143 77 ## 6 33 g 45 0.584 77 ## 7 45 f 1 0.0152 66 ## 8 45 j 42 0.636 66 ## 9 45 h 23 0.348 66 ## 10 241 f 12 0.176 68 ## 11 241 j 1 0.0147 68 ## 12 241 d 49 0.721 68 ## 13 241 g 6 0.0882 68 ## 14 315 j 15 0.214 70 ## 15 315 h 55 0.786 70 table.final = df_final%&gt;% group_by(stimuli,response)%&gt;% mutate(counter = 1)%&gt;% summarize(counter = sum(counter))%&gt;% mutate( percentage = round(counter/sum(counter),2), sum = sum(counter))%&gt;% select(stimuli,percentage, response)%&gt;% spread(stimuli, value = percentage) library(knitr) kable(table.final, caption = &quot;Percentage of choice&quot;) Table 6.1: Percentage of choice response 21 33 45 241 315 f 0.30 0.27 0.02 0.18 NA j NA NA 0.64 0.01 0.21 d 0.01 0.14 NA 0.72 NA g 0.68 0.58 NA 0.09 NA h NA NA 0.35 NA 0.79 "],
["build-your-own-function.html", "Chapter 7 Build your own function", " Chapter 7 Build your own function Combining the pipeline with different functions offered by tidyverse, you can have chunks of codes that fit into your specific needs of data analysis. But you may want to use these chunks again and again in the script you write. This will result in very long script. It is too bad for your eyes!! Thus we need to package these chunks into functions, so that every time we use them, we only need to refer to their names and put the dataframe in the parenthesis like we use other functions. That sound very cool! But is that difficult? noooooo! Not at all! Basically you only need to know the function structure and think of a name for your function. # function_name = function(input){ # do thing 1 # do thing 1 # return(output) # } # let&#39;s make a function for data cleaning data_clean = function(input){ #copy and paste the chunk we wrote earlier # change this line &quot;df_final = df %&gt;% to input %&gt;% # selecting the columns we need select(., subject = &quot;Subject&quot;, stimuli = &quot;tone.Trial.&quot;, response = &quot;insex1.RESP&quot;, response_rt = &quot;insex1.RT&quot;, block = &quot;Procedure.Block.&quot;, exp = ExperimentName)%&gt;% #filtering out useless data filter(block != &quot;pracproc&quot; &amp; !is.na(response) &amp; response != &quot;&quot;)%&gt;% # generating new variables based on old variables mutate(ISI = str_extract(exp, &quot;2000|500&quot;), block = recode(block, block1 = &quot;ss&quot;, block2 = &quot;ss&quot;, block3 = &quot;sd&quot;, block4 = &quot;sd&quot;, block5 = &quot;ds&quot;, block6 = &quot;ds&quot;, block7 = &quot;dd&quot;)) -&gt; output return(output) } # done!! Once you run the code, you will see a new function named data_clean appear in the environment tab on the right side of R-studio. This means a new function has been made. Now we can use our new function. library(tidyverse) participant_1 &lt;- read.csv(&quot;data/participant_1.csv&quot;) participant_2 &lt;- read.csv(&quot;data/participant_2.csv&quot;) #head(participant_1) #use the function participant_1_clean = data_clean(participant_1) head(participant_1_clean) ## subject stimuli response response_rt block exp ISI ## 1 402 33 f 672 ds Assim_main_chinese_500ms 500 ## 2 402 315 j 2831 ds Assim_main_chinese_500ms 500 ## 3 402 33 f 1041 ds Assim_main_chinese_500ms 500 ## 4 402 315 j 363 ds Assim_main_chinese_500ms 500 ## 5 402 21 f 1234 ds Assim_main_chinese_500ms 500 ## 6 402 45 j 322 ds Assim_main_chinese_500ms 500 # do the same thing for participant_2 participant_2_clean = data_clean(participant_2) head(participant_2_clean ) ## subject stimuli response response_rt block exp ## 1 418 241 d 968 sd assim_main_vietnamese_500ms ## 2 418 315 h 1036 sd assim_main_vietnamese_500ms ## 3 418 241 g 1171 sd assim_main_vietnamese_500ms ## 4 418 45 j 610 sd assim_main_vietnamese_500ms ## 5 418 21 g 214 sd assim_main_vietnamese_500ms ## 6 418 45 j 1945 sd assim_main_vietnamese_500ms ## ISI ## 1 500 ## 2 500 ## 3 500 ## 4 500 ## 5 500 ## 6 500 We can make funtions that meet our specific requirements and reuse them later. For example I want to generate a percentage of choice table for each participant. Since the requirements are too specific, I may not find a ready-to-use package with this function. Thus I can make one like this. # we reuse the chunk of codes we just made choice_table = function(input){ input%&gt;% group_by(stimuli,response)%&gt;% mutate(counter = 1)%&gt;% summarize(counter = sum(counter))%&gt;% mutate( percentage = round(counter/sum(counter),2), sum = sum(counter))%&gt;% select(stimuli,percentage, response)%&gt;% spread(stimuli, value = percentage) -&gt; output # do not forget this line return(output) } prt_2 = choice_table(participant_2_clean) prt_2 ## # A tibble: 4 x 6 ## response `21` `33` `45` `241` `315` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 d NA 0.11 NA 0.82 NA ## 2 g 1 0.89 NA 0.14 NA ## 3 h NA NA NA NA 0.96 ## 4 j NA NA 1 0.04 0.04 Now the question is: do we need two function data_clean and choice_table? The answer is that it depends on your data and your workflow. Sometime you can put the two functions together and get the results straight away. But you may want to have the clean data for other purposes. In that case, you may want to keep the two functions seperate. "],
["resources.html", "Chapter 8 Resources", " Chapter 8 Resources R is an open source software and R-studio is also free of charge. This facilitates a very friendly and active user community. Almost everything is free (except for some hard copy books but they usually have free online version). There are so many book you can google or amazon about data science with R, but I recommend this book which offers me many useful tips and examples, R for Data Science by Garrett Grolemund and Hadley Wickham and it is available online https://r4ds.had.co.nz/index.html. For those who want to have some cheatsheets of R functions, please go to this: https://www.rstudio.com/resources/cheatsheets/#keras For Digital Humanity specialists or language researchers, R offers a variaty of packages that can help you to make maps, do stylometric research on texts, do social network analysis and text mining and more. You can google the things you want to do and add “with R”. Nine out of ten times you will find a package or several packages. Have fun with R! "]
]
